---
theme: default
class: text-center
highlighter: shiki
lineNumbers: true
info: |
  ## Forutsigbar agentisk oppfÃ¸rsel med LangChain og MLflow
  
  Magnus RÃ¸dseth og HÃ¥vard Opheim â€” Capra Consulting @ Gjensidige
drawings:
  persist: false
transition: slide-left
title: Forutsigbar agentisk oppfÃ¸rsel med LangChain og MLflow
mdc: true
background: /banner.jpeg
---

# Forutsigbar agentisk oppfÃ¸rsel med LangChain og MLflow

<div class="text-xl font-semibold text-white drop-shadow-lg">Magnus RÃ¸dseth og HÃ¥vard Opheim</div>

<div class="text-lg text-white/90 drop-shadow-md">Capra Consulting @ Gjensidige</div>

<div class="absolute inset-0 bg-black/75 -z-1"></div>

<div class="abs-br m-6 flex gap-8 items-center bg-white rounded-lg px-4 py-2">
  <img src="/capra-logo.png" class="h-5" alt="Capra Consulting" />
  <img src="/gjensidige-logo.png" class="h-6" alt="Gjensidige" />
</div>

<!--
HÃ¥vard: 

Velkommen! Vi er Magnus og HÃ¥vard fra Capra.
I dag skal vi vise hvordan vi bruker LangChain og MLflow for Ã¥ bygge forutsigbare AI-agenter hos Gjensidige.

-->

---

# Hvem er vi?

<div class="flex gap-16 items-center justify-center mt-12">

<div class="flex flex-col items-center gap-4">
  <img src="/magnus.jpg" class="w-36 h-36 rounded-full object-cover border-4 border-gray-200 shadow-lg" alt="Magnus RÃ¸dseth" />
  <div class="text-center">
    <div class="font-bold text-lg">Magnus RÃ¸dseth</div>
    <div class="text-sm opacity-75">Utvikler i Capra Consulting</div>
  </div>
</div>

<div class="flex flex-col items-center gap-4">
  <img src="/havard.jpg" class="w-36 h-36 rounded-full object-cover border-4 border-gray-200 shadow-lg" alt="HÃ¥vard Opheim" />
  <div class="text-center">
    <div class="font-bold text-lg">HÃ¥vard Opheim</div>
    <div class="text-sm opacity-75">Utvikler i Capra Consulting</div>
  </div>
</div>

</div>

<div class="mt-12 text-center text-lg">

Utiled hos **Gjensidige**, hvor vi (blant annet) bygger agentiske AI-applikasjoner

</div>

<div class="abs-br m-6 flex gap-8 items-center bg-white rounded-lg px-4 py-2">
  <img src="/capra-logo.png" class="h-5" alt="Capra Consulting" />
  <img src="/gjensidige-logo.png" class="h-6" alt="Gjensidige" />
</div>

<!--
HÃ¥vard fortsetter
-->

---

# Dagens tema

**Forutsigbar agentisk oppfÃ¸rsel med LangChain og MLflow**

<div class="mt-8">

Agentiske applikasjoner kan oppleves som **uforutsigbare** og **vanskelig Ã¥ forholde seg til** som utviklere.

Vi viser hvordan vi bruker **MLflow** og **LangChain** for Ã¥ observere og guide adferden.

</div>

<div class="abs-br m-6 flex gap-8 items-center bg-white rounded-lg px-4 py-2">
  <img src="/capra-logo.png" class="h-5" alt="Capra Consulting" />
  <img src="/gjensidige-logo.png" class="h-6" alt="Gjensidige" />
</div>

<!--
HÃ¥vard: 
Temaet for denne presentasjonen er: Forutsigbar agentisk oppfÃ¸rsel med LangChain og MLflow.
Agentiske applikasjoner og store sprÃ¥kmodeller kan ofte oppleves som uforutsigbare og vanskelig Ã¥ forholde seg til som utviklere.
Vi skal vise dere hvordan vi bruker MLflow og LangChain hos Gjensidige for Ã¥ observere og guide adferden i agentiske applikasjoner.

Magnus:
Men fÃ¸rst â€” en rask introduksjon til verktÃ¸yene vi bruker, for de som ikke har utvikleet agentiske applikasjoner.
-->

---
layout: section
class: text-center
---

## Lynkurs: LangChain, agenter og samtaledesign

<!--
Magnus
-->

---

# Hva er LangChain?

<div class="grid grid-cols-3 gap-4 mt-8">

<v-click>
<div class="border rounded p-4 text-center">
  <div class="text-4xl mb-2">ğŸ“</div>
  <div class="font-bold">Prompts</div>
  <div class="text-sm opacity-75">Prompt-maler</div>
</div>
</v-click>

<v-click>
<div class="border rounded p-4 text-center">
  <div class="text-4xl mb-2">ğŸ¤–</div>
  <div class="font-bold">Modell</div>
  <div class="text-sm opacity-75">LLM-abstraksjoner</div>
</div>
</v-click>

<v-click>
<div class="border rounded p-4 text-center">
  <div class="text-4xl mb-2">âœ¨</div>
  <div class="font-bold">Output</div>
  <div class="text-sm opacity-75">Strukturert respons</div>
</div>
</v-click>

</div>

<v-click>

<div class="mt-8">

**LangChain** er et bibliotek som gjÃ¸r det enklere Ã¥ bygge applikasjoner med store sprÃ¥kmodeller.

I stedet for Ã¥ skrive rÃ¥ API-kall mot OpenAI, gir LangChain deg byggeblokker: prompt-maler, modellabstraksjoner, verktÃ¸y og minnehÃ¥ndtering.

</div>

</v-click>

<v-click>

<div class="mt-4 p-4 bg-blue-500 bg-opacity-10 rounded">

**LangGraph** er et sÃ¸sterbibliotek som lar deg bygge _agenter_.

</div>

</v-click>

<v-click>

<div class="mt-4 text-xl text-center opacity-75">

_Men hva er egentlig en agent?_

</div>

</v-click>

<!--
Magnus
-->

---

# Hva er en agent?

<div class="grid grid-cols-2 gap-8 mt-8">

<div>

## Vanlig LLM-integrasjon

```
Bruker â†’ SpÃ¸rsmÃ¥l
   â†“
Modell â†’ Svar
```

<div class="text-center mt-4 opacity-75">
Ã‰n runde. Ferdig.
</div>

</div>

<div>

## Agent

<v-clicks>

- ğŸ§  **Resonnere** over spÃ¸rsmÃ¥let og planlegge neste steg
- ğŸ› ï¸ **Bruke verktÃ¸y** â€” hente data, sÃ¸ke i dokumenter, kalle API-er
- ğŸ”„ **Iterere** â€” sjekke svaret sitt, prÃ¸ve pÃ¥ nytt
- ğŸ¤ **Delegere** â€” sende deloppgaver til andre agenter

</v-clicks>

</div>

</div>

<v-click>

<div class="mt-8 p-4 bg-green-500 bg-opacity-10 rounded">

**I praksis:** Du gir en LLM tilgang til verktÃ¸y og lar den selv bestemme _om_ og _nÃ¥r_ den skal bruke dem.

</div>

</v-click>

<!--
Magnus
-->

---

# Tre nÃ¸kkelprinsipper for agentisk samtaledesign

<v-clicks>

<div class="mt-8">

## 1. Intensjonsklassifisering

Hva prÃ¸ver brukeren Ã¥ oppnÃ¥? Vi klassifiserer hvert spÃ¸rsmÃ¥l for Ã¥ velge riktig behandling.

</div>

<div class="mt-8">

## 2. Kontekstinjeksjon

Vi henter relevant informasjon (fra dokumenter, databaser) og gir det til modellen _fÃ¸r_ den svarer.

</div>

<div class="mt-8">

## 3. Guardrails

Vi definerer hva agenten _ikke_ skal svare pÃ¥. Holdningen er: **"GjÃ¸r Ã©n ting, gjÃ¸r den bra."**

</div>

</v-clicks>

<!--
HÃ¥vard tar over. 
Nevn ogsÃ¥ at samtaler har en tre-struktur med noder og kanter hvor forskjellige verktÃ¸y og kontekst kan tilgjengeliggjÃ¸res i forskjellige noder
-->

---

# Hvordan koble pÃ¥ LangChain â€” i tre steg

````md magic-move
```python
# 1. Lag en modell
from langchain_openai import AzureChatOpenAI
model = AzureChatOpenAI(model="gpt-4.1")
```

```python
# 1. Lag en modell
from langchain_openai import AzureChatOpenAI
model = AzureChatOpenAI(model="gpt-4.1")

# 2. Lag en prompt
from langchain_core.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_messages([
    ("system", "Du er en hjelpsom assistent."),
    ("human", "{question}"),
])
```

```python
# 1. Lag en modell
from langchain_openai import AzureChatOpenAI
model = AzureChatOpenAI(model="gpt-4.1")

# 2. Lag en prompt
from langchain_core.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_messages([
    ("system", "Du er en hjelpsom assistent."),
    ("human", "{question}"),
])

# 3. Koble sammen og kjÃ¸r
chain = prompt | model
response = chain.invoke({"question": "Hva er hovedpunktene?"})
```
````

<style>
.slidev-code-magic-move .shiki-magic-move-container {
  font-size: 0.9rem !important;
  line-height: 1.6 !important;
}
</style>

<!--
HÃ¥vard fortsetter: LangChain + en sprÃ¥kmodell enkelt Ã¥ sette opp. Her er vÃ¥rt oppsett med Azure Open AI og LangChain i Python. 
-->

---

# Hva bÃ¸r man se etter og benchmarke?

<div class="grid grid-cols-3 gap-3 mt-6">

<v-click>
<div class="border rounded p-3">
  <div class="text-xl mb-1">â±ï¸</div>
  <div class="font-bold text-sm">Latency</div>
  <div class="text-xs opacity-75">Hvor lang tid tar hvert steg?</div>
</div>
</v-click>

<v-click>
<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ­</div>
  <div class="font-bold text-sm">Hallusinering</div>
  <div class="text-xs opacity-75">Finner modellen opp ting?</div>
</div>
</v-click>

<v-click>
<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ› ï¸</div>
  <div class="font-bold text-sm">VerktÃ¸ybruk</div>
  <div class="text-xs opacity-75">Valgte agenten riktig verktÃ¸y?</div>
</div>
</v-click>

<v-click>
<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ¯</div>
  <div class="font-bold text-sm">Kontekstrelevans</div>
  <div class="text-xs opacity-75">Hentet RAG riktige dokumenter?</div>
</div>
</v-click>

<v-click>
<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ“‰</div>
  <div class="font-bold text-sm">Regressjoner</div>
  <div class="text-xs opacity-75">DÃ¥rligere etter siste endring?</div>
</div>
</v-click>

</div>

<v-click>

<div class="mt-6 p-4 bg-purple-500 bg-opacity-10 rounded text-center">

**Dette er nÃ¸yaktig det vi skal vise dere hvordan vi mÃ¥ler â€” med MLflow.**

</div>

</v-click>

<!--
NÃ¥r du bygger med agenter, er det noen ting du bÃ¸r fÃ¸lge med pÃ¥ fra dag Ã©n:

- Latency â€” Hvor lang tid tar hvert steg? Agenter kan bli trege fordi de tar flere runder.
- Hallusinering â€” Finner modellen opp ting? Spesielt viktig nÃ¥r den svarer basert pÃ¥ brukerens dokumenter.
- VerktÃ¸ybruk â€” Valgte agenten riktig verktÃ¸y? Kalte den det med riktige parametere?
- Kontekstrelevans â€” Hentet RAG-modulen de riktige dokumentene, eller bare de mest populÃ¦re?
- Regressjoner â€” Ble svarkvaliteten dÃ¥rligere etter siste prompt-endring?

Dette er nÃ¸yaktig det vi skal vise dere hvordan vi mÃ¥ler â€” med MLflow.
-->

---
layout: section
class: text-center
---

## Hva bygger vi?

<!--
Magnus intrduserer hva vi bygger
-->

---

# Caset: En agentisk dokumentassistent

<div class="grid grid-cols-2 gap-8">

<div>

<v-clicks>

Tenk deg at du bygger en chatbot der brukere kan:

- Laste opp komplekse dokumenter (rapporter, kontrakter, manualer)
- Stille spÃ¸rsmÃ¥l og fÃ¥ svar basert pÃ¥ innholdet
- FÃ¥ AI-genererte oppsummeringer og anbefalinger

**Utfordringen:**
- Hvordan vet du at agenten fungerer?
- At den ikke hallusinerer?
- At RAG henter riktig kontekst?

</v-clicks>

</div>

<img src="/screenshots/application.png" class="rounded-lg shadow-lg mt-4 mx-auto" alt="MLflow UI â€” Traces-oversikten" />

</div>

<!--
Magnus.. 
-->

---

# Teknisk arkitektur â€” helt overordnet

```mermaid {scale: 0.75}
graph LR
    subgraph Frontend
        A[React Router Frontend]
    end
    
    subgraph Backend["FastAPI Backend"]
        B[Guardrails]
        C[RAG]
        D[Conversation Memory]
        E[Tools]
    end
    
    subgraph Infra["Infrastructure"]
        F[PostgreSQL + pgvector]
        G[Azure OpenAI]
        H[MLflow]
    end
    
    A --> Backend
    Backend --> Infra
```

<v-click>

**Tech-stacken:**
- Python, LangGraph + LangChain for agentorkestrering
- Azure OpenAI
- PostgreSQL med pgvector for data og RAG
- **MLflow for observabilitet**

</v-click>

<!--
Magnus
-->

---
layout: section
class: text-center
---

## Observabilitet og sporbarhet

<!--
HÃ¥vard: ogsÃ¥ over pÃ¥ hvordan vi fÃ¸lger med pÃ¥ adferden til agenten ut mot brukerne. Dette er en ganske kritisk del av innsikten vi samler for Ã¥ vite om produktet skaper verdi eller ikke.
-->

---

# Hvorfor er observabilitet viktig?

Vi _mÃ¥_ vite:

<v-clicks>

<div class="mt-8 grid grid-cols-3 gap-4">

<div class="border rounded p-4">
  <div class="text-3xl mb-2">ğŸ‘¥</div>
  <div class="font-bold mb-2">Brukeratferd</div>
  <div class="text-sm">Hvordan bruker brukere AI-delene? Hva lurer de faktisk pÃ¥?</div>
</div>

<div class="border rounded p-4">
  <div class="text-3xl mb-2">ğŸ¤–</div>
  <div class="font-bold mb-2">AgentoppfÃ¸rsel</div>
  <div class="text-sm">Svarer den bra? Eller bare slop?</div>
</div>

<div class="border rounded p-4">
  <div class="text-3xl mb-2">ğŸ“„</div>
  <div class="font-bold mb-2">Ekstraksjonskvalitet</div>
  <div class="text-sm">Finner AI-en all relevant informasjon</div>
</div>

</div>

</v-clicks>

<v-click>

<div class="mt-8 p-4 bg-yellow-500 bg-opacity-10 rounded">

**Vi bruker MLflow til Ã¥ teste og iterere ettervhert som vi lÃ¦rer mer om brukerne vÃ¥re**

</div>

</v-click>

<!--
SpÃ¸rsmÃ¥l vi stiller oss:

1. Hvordan bruker folk AI-delene? Stiller de spÃ¸rsmÃ¥l vi ikke forventet? Treffer RAG-modulen riktig kontekst?
2. Hvordan oppfÃ¸rer agentene seg? Klassifiserer de intensjon riktig? Hallusinerer de?
3. Fungerer ekstraheringen? Finner AI-en alle relevante funn i dokumentene?
-->

---

# MLflow UI â€” Traces-oversikten

<img src="/screenshots/mlflow-traces-overview-blurred.png" class="rounded-lg shadow-lg mt-4 mx-auto h-96" alt="MLflow UI â€” Traces-oversikten" />

<!--
Hvis du spinner opp en docker image med MLflow sÃ¥ fÃ¥r du noe sÃ¥nt som dette ut av boksen. Men du mÃ¥ confige bittelitt for Ã¥ fÃ¥ data inn, men ikke sÃ¥ mye.
-->

---

# Slik setter vi opp MLflow-tracing

`init_mlflow()`:

````md magic-move
```python
# api/src/observability/tracing.py

import mlflow
from src.config import get_settings

def init_mlflow() -> None:
    """Initialize MLflow tracking."""
    settings = get_settings()
```

```python
# api/src/observability/tracing.py

import mlflow
from src.config import get_settings

def init_mlflow() -> None:
    """Initialize MLflow tracking."""
    settings = get_settings()

    # Sett tracking URI â€” peker pÃ¥ MLflow-serveren
    mlflow.set_tracking_uri(settings.mlflow_tracking_uri)

    # Sett eksperiment â€” alle traces havner her
    mlflow.set_experiment(settings.mlflow_experiment_name)
```

```python {16-17}
# api/src/observability/tracing.py

import mlflow
from src.config import get_settings

def init_mlflow() -> None:
    """Initialize MLflow tracking."""
    settings = get_settings()

    # Sett tracking URI â€” peker pÃ¥ MLflow-serveren
    mlflow.set_tracking_uri(settings.mlflow_tracking_uri)

    # Sett eksperiment â€” alle traces havner her
    mlflow.set_experiment(settings.mlflow_experiment_name)

    # Ã‰n linje â€” dette er magien
    mlflow.langchain.autolog(log_traces=True)
```
````

<!--
Alt begynner med Ã©n funksjon: init_mlflow(). Her er koden:

FÃ¸rst setter vi tracking URI â€” dette peker pÃ¥ MLflow-serveren.
SÃ¥ setter vi eksperiment â€” alle traces havner her.

Og sÃ¥ kommer magien: mlflow.langchain.autolog(log_traces=True)

Den siste linjen er nÃ¸kkelen. Denne ene linjen gjÃ¸r at alle LangChain- og LangGraph-kall automatisk blir tracet.
Hver node i grafen, hvert LLM-kall, hvert verktÃ¸ykall â€” alt logges til MLflow uten at vi skriver en eneste dekoratÃ¸r eller wrapper.

Denne funksjonen kalles nÃ¥r FastAPI-serveren starter opp, i main.py.
Vi kjÃ¸rer med 100% sampling i MVP-fasen â€” hvert eneste brukerbudskap blir tracet.
-->

---

# Hva tracer vi â€” og hva ser vi?

## Chat-agenten: En LangGraph-graf

```mermaid {scale: 0.6}
graph LR
    Start(("ğŸŸ¢")) --> validate_input
    validate_input -->|avvist| End(("ğŸ”´"))
    validate_input -->|ok| classify_intent
    classify_intent -->|trenger kontekst| retrieve_context
    classify_intent -->|direkte svar| generate_response
    retrieve_context --> generate_response
    generate_response --> End
```

<v-click>

Med `mlflow.langchain.autolog()` kan vi i MLflow UI se **hvert steg** som en span i tracet.

</v-click>

<!--
Chat-agenten vÃ¥r er definert som en LangGraph StateGraph. Slik ser den ut:

Start â†’ validate_input â†’ classify_intent â†’ retrieve_context (hvis nÃ¸dvendig) â†’ generate_response â†’ End

Takket vÃ¦re mlflow.langchain.autolog() kan vi i MLflow UI se hvert steg som en span i tracet.
-->

---

# MLflow UI â€” Utvidet trace

<img src="/screenshots/mlflow-trace-expanded-2.png" class="rounded-lg shadow-lg mt-4 mx-auto h-96" alt="MLflow UI â€” Utvidet trace" />

<!--
Her ser dere et utvidet trace i MLflow UI â€” span-treet som viser:
- validate_input â€” Ble meldingen avvist av guardrails?
- classify_intent â€” Hva ble intensjonen?
- retrieve_context â€” Hvilke dokumentchunks ble hentet fra vektordatabasen?
- generate_response â€” Hva var den fulle prompten, og hva svarte LLM-en?

For hver span ser vi input, output, og latency. Uten Ã¥ skrive en eneste linje observabilitetskode utover autolog().
-->

---

# Agenttilstanden â€” hva som flyter gjennom grafen

Tilstanden som flyter mellom nodene er definert som en TypedDict:

```python
# api/src/agent/state.py

class AgentState(TypedDict, total=False):
    messages: Annotated[list[BaseMessage], add_messages]
    conversation_id: uuid.UUID | None
    resolved_context: dict | None        # Bruker-/dokumentkontekst
    retrieved_docs: list[Document]       # RAG-resultater
    sources: list[dict]                  # Kildemetadata for siteringer
    current_step: str                    # Observabilitet
    intent: str | None                   # Klassifisert intensjon
    needs_retrieval: bool                # Trenger vi RAG?
    is_rejected: bool                    # Avvist av guardrails?
```

<v-click>

<div class="mt-4 p-4 bg-blue-500 bg-opacity-10 rounded">

Alt dette er synlig i hvert trace og vi kan se nÃ¸yaktig hva grafen "tenkte" i hvert steg.

</div>

</v-click>

<!--
Tilstanden som flyter mellom nodene er definert som en TypedDict.

Her ser dere alle feltene â€” messages, conversation_id, resolved_context, retrieved_docs, sources, current_step, intent, needs_retrieval, is_rejected.

Alt dette er synlig i hvert trace â€” vi kan se nÃ¸yaktig hva grafen "tenkte" i hvert steg.
-->

---

# Ekstraheringsagenten: Deep Agents med subagenter

<div class="text-sm">

For dokumentanalyse bruker vi **Deep Agents** som abstraksjonslag over LangChain og LangGraph.

</div>

<v-click>

```python
from deepagents import create_deep_agent

def create_extraction_agent(...) -> Runnable:
    model = get_extraction_model()
    tools = [...]           # verktÃ¸y for parsing, lagring, fremdrift
    subagent = [...]        # subagent for ekstraksjon av strukturerte funn

    return create_deep_agent(
        model=model,
        tools=tools,
        subagents=subagent,
        system_prompt=ORCHESTRATOR_SYSTEM_PROMPT,
    )
```

</v-click>

<v-click>

<div class="mt-2 p-3 bg-purple-500 bg-opacity-10 rounded text-sm">

Fordi Deep Agents bygger pÃ¥ LangChain, fÃ¥r vi **automatisk tracing av hele orkestreringsagenten og alle subagent-kall** via den samme `autolog()`-linjen.

</div>

</v-click>

<!--
Magnus hopper inn igjen
-->

---

# MLflow UI â€” Ekstraheringsagent trace

<img src="/screenshots/mlflow-extraction-trace-3.png" class="rounded-lg shadow-lg mt-4 mx-auto h-96" alt="MLflow UI â€” Ekstraheringsagent trace" />

<!--
Magnus fortsetter
-->

---

# Evaluering â€” Custom scorers

Tracing gir oss innsikt i _hva_ som skjer. Men vi trenger ogsÃ¥ Ã¥ mÃ¥le _hvor bra_ det fungerer.

Vi har bygget fire tilpassede scorers med **MLflow GenAI Evaluation**:

<v-clicks>

<div class="grid grid-cols-2 gap-4 mt-4">

<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ¯</div>
  <div class="font-bold text-sm">GroundednessScorer</div>
  <div class="text-xs opacity-75">Er svaret forankret i konteksten? Fanger opp hallusinasjoner.</div>
</div>

<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ’¡</div>
  <div class="font-bold text-sm">HelpfulnessScorer</div>
  <div class="text-xs opacity-75">Adresserer svaret brukerens spÃ¸rsmÃ¥l?</div>
</div>

<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ“š</div>
  <div class="font-bold text-sm">RetrievalRelevanceScorer</div>
  <div class="text-xs opacity-75">Er den hentede konteksten relevant for spÃ¸rsmÃ¥let?</div>
</div>

<div class="border rounded p-3">
  <div class="text-xl mb-1">ğŸ‡³ğŸ‡´</div>
  <div class="font-bold text-sm">NorwegianLanguageScorer</div>
  <div class="text-xs opacity-75">Svarer agenten pÃ¥ norsk?</div>
</div>

</div>

</v-clicks>

<!--
Magnus
-->

---

# GroundednessScorer â€” Kodeeksempel

```python {*|4-6|7-8|10|12-16}{lines:true}
from mlflow.genai import scorer
from mlflow.entities import Feedback

def GroundednessScorer():
    @scorer
    def groundedness(*, inputs, outputs, context=None, **kwargs):
        if intent in ["REJECTED", "GENERAL_CHAT"]:
            return None                    # hopp over irrelevante intensjoner

        result = _groundedness_judge(...)  # LLM-dommer vurderer forankring

        return Feedback(
            value=...,      # 1.0 = forankret, 0.5 = delvis, 0.0 = hallusinert
            rationale=...,  # forklaring fra dommeren
        )
    return groundedness
```

<!--
Her er koden for GroundednessScorer.
-->

---

# KjÃ¸re evalueringer â€” CLI

Vi har en CLI for Ã¥ kjÃ¸re evalueringer mot utvalgte testdatasett eller produksjons-traces:

```bash
# Evaluer mot utvalgt testdatasett (17 testtilfeller)
uv run --directory api python -m src.evaluation.cli conversation
```

<v-click>

```bash
# Evaluer de siste 100 produksjons-tracene
uv run --directory api python -m src.evaluation.cli conversation \
    --from-traces --trace-count 100
```

</v-click>

<v-click>

```bash
# Evaluer med 20% sampling fra siste uke
uv run --directory api python -m src.evaluation.cli conversation \
    --from-traces --start-date 2026-01-01 --sample-rate 0.2
```

</v-click>

<!--
Magnus...
-->

---

# MLflow UI â€” Evaluation results

<img src="/screenshots/mlflow-evaluation-results-3.png" class="rounded-lg shadow-lg mt-4 mx-auto h-96" alt="MLflow UI â€” Evaluation results" />

<!--
Resultatene havner i MLflow UI med:
- Aggregerte metrikker â€” pass rate, gjennomsnittsscore per scorer
- Individuelle testresultater med rationale
- Koblet til traces â€” du kan klikke deg ned i nÃ¸yaktig hva agenten gjorde
-->

---

# Utvalgte testdatasett

Vi har definert testtilfeller som dekker ulike scenarioer:

```python
# api/src/evaluation/datasets/conversation.py

DOCUMENT_TEST_CASES = [
    ConversationTestCase(
        id="doc_001",
        question="Hva er hovedfunnene i rapporten?",
        expected_intent="DOCUMENT_QUESTION",
        context="Rapport fra 2024. Tre kritiske funn identifisert.",
        reference_answer="Rapporten identifiserer tre kritiske funn.",
    ),
]

OUT_OF_SCOPE_TEST_CASES = [
    ConversationTestCase(
        id="oos_001",
        question="Kan du hjelpe meg med matlagning?",
        expected_intent="REJECTED",
    ),
]
```

<v-click>

<div class="mt-2 p-3 bg-blue-500 bg-opacity-10 rounded text-sm">

Disse testtilfellene kan kjÃ¸res som **regresjonstester** â€” etter hver endring i prompts eller agentkode kan vi verifisere at kvaliteten holder seg.

</div>

</v-click>

<!--
Magnus
-->

<style>
.slidev-code-wrapper {
  font-size: 0.52em !important;
}
</style>

---

# Produksjons-traces â†’ Evaluering â€” Flyt

```mermaid {scale: 0.8}
graph LR
    A[Produksjons-traces<br/>MLflow] --> B[Filtrer/sample]
    B --> C[Evalueringsdatasett]
    C --> D[Scorers]
    D --> E[Resultater<br/>tilbake i MLflow UI]
```

<!--
Magnus:
-->

---
layout: section
class: text-center
---

## Utvikling og hosting

<!--
HÃ¥vard tar resten
-->

---

# Lokal utvikling â€” Docker Compose

<div class="text-sm">

Med Docker Compose

</div>

```yaml {*|7-17}{lines:true}
# docker-compose.yml
services:
  postgres:
    image: pgvector/pgvector:pg16
    ports: ["5432:5432"]

  mlflow:
    build:
      dockerfile: docker/mlflow.Dockerfile
    command: >
      mlflow server
      --host 0.0.0.0 --port 5000
      --backend-store-uri postgresql://...@postgres:5432/mlflow
      --serve-artifacts
    ports: ["5000:5000"]
    depends_on:
      postgres: { condition: service_healthy }
```

<!--
For lokal utvikling er MLflow del av vÃ¥r Docker Compose.

Vi har PostgreSQL med pgvector, MLflow som kjÃ¸rer som en egen container med PostgreSQL som backend-store, og Redis.

make db-up starter alt. http://localhost:5000 gir deg MLflow UI.
-->

---

# Produksjon â€” Hosting-alternativer

For produksjon kan MLflow hostes pÃ¥ flere mÃ¥ter.

<v-clicks>

<div class="mt-8">

**Databricks (vÃ¥rt valg)**
- MLflow har native integrasjon med Databricks
- Skalerer automatisk
- Managed service â€” ingen infrastruktur Ã¥ vedlikeholde

</div>

<div class="mt-8">

**Alternativer for produksjonsskala (fra MLflows dokumentasjon):**
- AWS SageMaker
- Azure Machine Learning
- Nebius (ğŸ‡ªğŸ‡º)
- GCP (GKE)

</div>

</v-clicks>

<!--
For produksjon kan MLflow hostes pÃ¥ flere mÃ¥ter.

Databricks er vÃ¥rt valg fordi:
- MLflow har native integrasjon med Databricks
- Skalerer automatisk
- Managed service â€” ingen infrastruktur Ã¥ vedlikeholde

Fra MLflows egen dokumentasjon â€” alternativer for produksjonsskala:
AWS SageMaker, Azure Machine Learning, Nebius, GCP.
-->

---
layout: section
class: text-center
---

## Oppsummering og veien videre

<!--
La oss oppsummere det vi har gÃ¥tt gjennom.
-->

---

# Den store idÃ©en

<v-click>

<div class="text-2xl text-center mt-12 mb-12 p-8 bg-purple-500 bg-opacity-10 rounded">

Ved Ã¥ dumpe all denne innsikten â€” hvert agentresonnement, hvert RAG-oppslag, hvert evalueringsresultat â€” inn i MLflow, kan vi gjÃ¸re **dataanalyse pÃ¥ bruker- og agentatferd**.

</div>

</v-click>

<v-click>

<div class="text-2xl text-center mt-12 p-8 bg-blue-500 bg-opacity-10 rounded">

Vi kan tweake systemet vÃ¥rt, og skape en brukeropplevelse som brukerne faktisk _elsker_.

</div>

</v-click>

<!--
Poenget med alt dette er:

Ved Ã¥ dumpe all denne innsikten â€” hvert agentresonnement, hvert RAG-oppslag, hvert evalueringsresultat â€” inn i MLflow, kan vi gjÃ¸re dataanalyse pÃ¥ bruker- og agentatferd.

Vi kan tweake systemet vÃ¥rt, og skape en brukeropplevelse som brukerne faktisk elsker.
-->

---

# Feedback-loopen

<div class="border rounded-lg p-3 bg-gray-50 mt-2 text-left max-w-lg mx-auto">
  <div class="text-xs text-gray-500 mb-1">AI-assistent</div>
  <div class="text-sm text-gray-800 blur-sm">Basert pÃ¥ tilstandsrapporten din anbefaler jeg at du sjekker dreneringen rundt grunnmuren, spesielt...</div>
  <div class="flex gap-2 mt-2">
    <button class="px-2 py-1 rounded border text-xs bg-white">ğŸ‘</button>
    <button class="px-2 py-1 rounded border text-xs bg-white">ğŸ‘</button>
    <span class="text-xs text-gray-400 ml-2 mt-1">Var dette svaret nyttig?</span>
  </div>
</div>

<v-click>

<div class="text-sm mt-2">

Par dette med et **tilbakemeldingssystem** fra brukerne â€” og vi har en transparent mÃ¥te Ã¥ korrigere agentenes oppfÃ¸rsel i produksjon.

</div>

</v-click>

<v-click>

```mermaid {scale: 0.55}
graph LR
    A[Bruker] --> B[Feedback ğŸ‘/ğŸ‘]
    B --> C[Database]
    C --> D[MLflow Assessment]
    D --> E[Evaluering]
    E --> F[Prompt-forbedring]
    F --> G[Bedre svar]
    G --> A
```

</v-click>

<!--
Par dette med et tilbakemeldingssystem fra brukerne â€” tommel opp/ned og kommentarer i chatten, eller flagging av at en ekstraksjon er helt feil â€” og vi har en transparent mÃ¥te Ã¥ korrigere agentenes oppfÃ¸rsel i produksjon.

Denne sirkelen â€” fra brukerinteraksjon til observabilitet til evaluering til forbedring â€” er det som gjÃ¸r det mulig Ã¥ skalere agentiske lÃ¸sninger med selvtillit.
-->

---

# Oppsummert

<div class="text-sm">

| Hva                     | Hvordan                                    | VerktÃ¸y            |
| ----------------------- | ------------------------------------------ | ------------------ |
| Automatisk tracing      | `mlflow.langchain.autolog()`               | MLflow + LangChain |
| Agent-orkestrering      | LangGraph StateGraph                       | LangGraph          |
| Dokumentekstraksjon     | Deep Agents med subagenter                 | `deepagents`       |
| KvalitetsmÃ¥ling         | Custom scorers + `mlflow.genai.evaluate()` | MLflow GenAI       |
| Produksjonsmonitorering | Trace-basert evaluering med sampling       | MLflow traces API  |
| Bruker-feedback         | Thumbs up/down â†’ MLflow assessments        | FastAPI + MLflow   |

</div>

<v-click>

<div class="mt-4 p-3 bg-green-500 bg-opacity-10 rounded text-center text-sm">

**Ã‰n linje kode gir oss full observabilitet.** Et sett med scorers gir oss systematisk kvalitetsmÃ¥ling. Og muligheten til Ã¥ evaluere produksjons-traces gir oss den tryggheten vi trenger for Ã¥ skalere.

</div>

</v-click>

<!--
La meg oppsummere:

Automatisk tracing med mlflow.langchain.autolog() â€” MLflow + LangChain
Agent-orkestrering med LangGraph StateGraph â€” LangGraph
Dokumentekstraksjon med Deep Agents med subagenter â€” deepagents
KvalitetsmÃ¥ling med custom scorers og mlflow.genai.evaluate() â€” MLflow GenAI
Produksjonsmonitorering med trace-basert evaluering med sampling â€” MLflow traces API
Bruker-feedback med thumbs up/down til MLflow assessments â€” FastAPI + MLflow

Ã‰n linje kode gir oss full observabilitet.
Et sett med scorers gir oss systematisk kvalitetsmÃ¥ling.
Og muligheten til Ã¥ evaluere produksjons-traces gir oss den tryggheten vi trenger for Ã¥ skalere.
-->

---
layout: center
class: text-center
---

# Takk for oppmerksomheten!

## SpÃ¸rsmÃ¥l?

<div class="mt-12">

**Magnus RÃ¸dseth og HÃ¥vard Opheim**

Capra Consulting @ Gjensidige

</div>

<div class="abs-br m-6 flex gap-8 items-center bg-white rounded-lg px-4 py-2">
  <img src="/capra-logo.png" class="h-5" alt="Capra Consulting" />
  <img src="/gjensidige-logo.png" class="h-6" alt="Gjensidige" />
</div>

<!--
Takk for oppmerksomheten! SpÃ¸rsmÃ¥l?
-->

